{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bd64x0aGmTbE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Identifying Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAc27jkomTbG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# We will use the orders table from Super Store for these tasks\n",
    "orders = pd.read_csv('data/datasets/orders.csv')\n",
    "\n",
    "\n",
    "# A. Start with some exploratory analysis methods to inspect the data\n",
    "orders.columns\n",
    "orders.shape\n",
    "pd.DataFrame(orders.dtypes, columns=[\"DataTypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "En6Rgnl4mTbI"
   },
   "outputs": [],
   "source": [
    "# B. Which column has the most missing data? Sort the columns by sum of null values\n",
    "orders.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOzLvkVimTbJ"
   },
   "outputs": [],
   "source": [
    "# C. Looks like postal_code is our biggest problem, along with region_id\n",
    "# Use a combination of filtering, isnull, and sum to count how many rows are missing both columns\n",
    "orders[orders['postal_code'].isnull()]['region_id'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElHAxX5TmTbL"
   },
   "outputs": [],
   "source": [
    "# D. Let's drop the region_id nulls from the dataframe before proceeding\n",
    "orders.dropna(subset=['region_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tsXfbFGmTbM"
   },
   "outputs": [],
   "source": [
    "# E. It's the dream scenario! The IT team confirms all missing postal_code values should be 10001.0\n",
    "orders['postal_code'].fillna(10001.0, inplace=True)\n",
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cleaning Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90j-V9zkmTbN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# A. Write a profit_margin function that accepts a row of data, which is a dictionary\n",
    "#    It should return the result of dividing the profit column by the sales column (i.e. profit/sales)\n",
    "def profit_margin(row):\n",
    "    return row['profit'] / row['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2ubcz_4mTbO"
   },
   "outputs": [],
   "source": [
    "# B. Create a new column in the orders dataframe called 'profit_margin' by applying the profit margin function row-by-row\n",
    "orders['profit_margin'] = orders.apply(profit_margin, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilnQ-FMdmTbP"
   },
   "outputs": [],
   "source": [
    "# C. Use the same process to create a new column called margin_category\n",
    "# If the profit_margin is less than 0, the margin_category should be \"unprofitable\"\n",
    "# If the profit_margin is 0, the margin_category should be \"break even\"\n",
    "# If the profit_margin is above 0, the margin_category should \"profitable\"\n",
    "def margin_categorization(row):\n",
    "    if row['profit_margin'] > 0:\n",
    "        return \"profitable\"\n",
    "    elif row['profit_margin'] == 0:\n",
    "        return \"break even\"\n",
    "    else:\n",
    "        return \"unprofitable\"\n",
    "orders['margin_category'] = orders.apply(margin_categorization, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87wC6ZHMmTbP"
   },
   "outputs": [],
   "source": [
    "# D. How many of our orders were unprofitable?\n",
    "orders[orders['margin_category'] == \"unprofitable\"].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GroupBy Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjzfGejimTbR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Segment the following data and explore aggregate values to answer the following questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOqSCiDymTbR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A. Which discount results in the highest mean order quantity?\n",
    "orders.groupby('discount')['quantity'].mean().sort_values(ascending=False).iloc[[0]].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvfkxNDgmTbS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B. Which product has the highest mean price discount applied?\n",
    "orders.groupby('product_id')['discount'].mean().sort_values(ascending=False).iloc[[0]].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Joining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNjl67mamTbS"
   },
   "outputs": [],
   "source": [
    "\n",
    "# The below example joins our first two dataframes by their shared column, Symbol\n",
    "openprice = pd.DataFrame({'Symbol': ['AAPL', 'DHR', 'DAL', 'AMZN'], 'OpenPrice': [217.51, 96.54, 51.45, 1703.34]})\n",
    "wkhigh = pd.DataFrame({'Symbol': ['DAL', 'AMZN', 'AAPL', 'DHR'], '52wkHigh': [60.79, 2050.49, 233.47, 110.11]})\n",
    "combined = pd.merge(openprice, wkhigh, how=\"left\", left_on='Symbol', right_on='Symbol')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYZNdET7mTbT",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A. Join the stockname dataframe to our combined result and print the result\n",
    "stockname = pd.DataFrame({'Symbol': ['AMZN', 'DHR', 'DAL', 'AAPL'], 'Name': ['Amazon', 'Danaher', 'Delta Airlines', 'Apple']})\n",
    "combined = pd.merge(combined, stockname, how=\"left\", on=\"Symbol\")\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZPva1vVmTbT"
   },
   "outputs": [],
   "source": [
    "# B. Use the following tables from Super Store\n",
    "products = pd.read_csv('data/datasets/products.csv')\n",
    "orders = pd.read_csv('data/datasets/orders.csv')\n",
    "returns = pd.read_csv('data/datasets/returns.csv')\n",
    "regions = pd.read_csv('data/datasets/regions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgjNtCePmTbU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# i. We want to join the products and orders dataframes. \n",
    "#    Explore both dataframes to identify the common column between them\n",
    "#    Use a left join to combine the tables in a dataframe named orders_with_products\n",
    "orders_with_products = pd.merge(left=products, right=orders, how=\"left\", on=\"product_id\")\n",
    "orders_with_products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOPdk0OYmTbV"
   },
   "outputs": [],
   "source": [
    "# ii. Left join the orders_with_products and returns dataframes\n",
    "orders_with_products_and_returns = pd.merge(left=orders_with_products, right=returns, how=\"left\", on=\"order_id\")\n",
    "orders_with_products_and_returns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyNKHYLymTbV"
   },
   "outputs": [],
   "source": [
    "# iii. Finally, add the region data to our combined dataframe\n",
    "orders_with_products_and_returns_and_regions = pd.merge(left=orders_with_products_and_returns, right=regions, how=\"left\", on=\"region_id\")\n",
    "orders_with_products_and_returns_and_regions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGTSKsTAmTbX"
   },
   "outputs": [],
   "source": [
    "# iv. Let's use this combined dataframe to determine the salesperson generating the most profit\n",
    "orders_with_products_and_returns_and_regions.groupby('salesperson')['profit'].sum().sort_values(ascending=False).iloc[[0]].index[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "13. Cleaning and Combining Data â€“ Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
